{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and inspect keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./weights/keras_export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work: https://github.com/keras-team/keras/issues/11746\n",
    "embedding = keras.Model(inputs=model.input, outputs=model.get_layer(\"activation_45\"), name=\"embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround: sequential api\n",
    "sequential = keras.Sequential()\n",
    "sequential.add(model.get_layer(\"input_1\"))\n",
    "sequential.add(model.get_layer(\"activation_45\"))\n",
    "sequential.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.random.uniform((1,112,8,8))\n",
    "sequential.predict(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export keras model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, 112, 8, 8), tf.float32, name=\"input\"),)\n",
    "output_path = model.name + \".onnx\"\n",
    "tf2onnx.convert.from_keras(model=model, opset=12, input_signature=spec, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/microsoft/onnxruntime/issues/3229\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "sess = onnxruntime.InferenceSession(output_path)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "scores = sess.run([output_name], {input_name: np.random.random((1,112,8,8)).astype(np.float32)})[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export onnx model to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"model.onnx\")  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(\"tf/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export onnx model to pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "from onnx2torch.converter import convert\n",
    "\n",
    "# Path to ONNX model\n",
    "onnx_model_path = 'model.onnx'\n",
    "\n",
    "# Or you can load a regular onnx model and pass it to the converter\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "torch_model_2 = convert(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model_2.forward(torch.rand(112,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch_model_2, \"pytorch/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
